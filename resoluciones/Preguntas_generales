
Tengo casi nula experiencia en AWS y linux


Ejercicio 3 - Preguntas en general (Soluciones de pocas líneas)
a- ¿Qué formas de hacer scheduling de una tarea en linux conoce?

Con crontab, agregando la periodicidad en formato * * * * * y luego la ubicación del archivo con el código


b- ¿Cómo y con qué comandos guardaría la mayor cantidad de detalle sobre las salidas de un script
python que desea ejecutar de forma diaria a las 6AM?

Se podría crear un logger, que manda información de corrida a alguna tabla.
O un .txt con la información


c- ¿Qué comando o serie de comandos utilizaría para subir todos los contenidos de un directorio a un
bucket de S3?

Con AWS CLI:
$ aws s3 cp myfolder s3://mybucket/myfolder --recursive

d- Si una instancia de Redshift utilizada para reporting se está quedando sin espacio y se impone la
necesidad de sacar algunos datos antiguos de la base, pero a pesar de que los datos de más de seis
meses de antigüedad no se utilicen para reporting, se los requiere para entrenar y validar modelos
predictivos, además de hacer algunos análisis ad-hoc en SQL a un precio razonable considerando
tanto infraestructura como costos de consultas ¿Que tipo de solución propondría para poder
consultar los datos usando servicios cloud en AWS? Intentar ser lo más descriptivo posible.

Desconozco de AWS, tengo que hacer los cursos.
Igualmente se podría reducir la tabla, preguntando si realmente son necesarias todas las columnas o la
posibilidad de armar una muestra de la misma, reduciendo considerablemente la cantidad de filas
